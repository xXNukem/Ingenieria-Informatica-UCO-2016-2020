{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 1 y 2:</b></br>\n",
    "1. Seleccione tres algoritmos clasificación de los disponibles en scikit-learn.\n",
    "2. Para cada uno de estos tres métodos de clasificación realice los siguientes pasos usando validación cruzada de 10\n",
    "particiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "Se han seleccionado los algoritmos KNN, SVM y Arbol de decisión, a los cuales se les ha aplicado la validación cruzada con 10 particiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 2.1: </b></br>\n",
    "Aplique el método base a cada uno de los conjuntos y anote los resultados obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando método base: \n",
      "Base de datos: contact-lenses.arff\n",
      "Puntuacion KNN\n",
      "[0.5        0.75       0.5        0.75       0.66666667 0.\n",
      " 1.         1.         1.         1.        ]\n",
      "----------------\n",
      "Puntuacion SVM\n",
      "[0.5        0.5        0.5        0.5        0.66666667 1.\n",
      " 1.         1.         1.         1.        ]\n",
      "-----------------\n",
      "Puntuacion TREE\n",
      "[1.         0.75       1.         1.         0.33333333 0.\n",
      " 1.         1.         1.         1.        ]\n",
      "-----------------------------------------------\n",
      "Base de datos: diabetes.arff\n",
      "Puntuacion KNN\n",
      "[0.67532468 0.79220779 0.71428571 0.67532468 0.66233766 0.74025974\n",
      " 0.7012987  0.79220779 0.71052632 0.75      ]\n",
      "----------------\n",
      "Puntuacion SVM\n",
      "[0.64935065 0.64935065 0.64935065 0.64935065 0.64935065 0.64935065\n",
      " 0.64935065 0.64935065 0.65789474 0.65789474]\n",
      "-----------------\n",
      "Puntuacion TREE\n",
      "[0.64935065 0.74025974 0.7012987  0.5974026  0.68831169 0.64935065\n",
      " 0.83116883 0.80519481 0.63157895 0.73684211]\n",
      "-----------------------------------------------\n",
      "Base de datos: glass.arff\n",
      "Puntuacion KNN\n",
      "[0.56521739 0.65217391 0.65217391 0.86363636 0.68181818 0.31818182\n",
      " 0.71428571 0.6        0.75       0.61111111]\n",
      "----------------\n",
      "Puntuacion SVM\n",
      "[0.65217391 0.52173913 0.69565217 0.86363636 0.59090909 0.5\n",
      " 0.66666667 0.7        0.65       0.83333333]\n",
      "-----------------\n",
      "Puntuacion TREE\n",
      "[0.7826087  0.60869565 0.69565217 0.68181818 0.63636364 0.54545455\n",
      " 0.76190476 0.65       0.75       0.72222222]\n",
      "-----------------------------------------------\n",
      "Base de datos: ionosphere.arff\n",
      "Puntuacion KNN\n",
      "[0.80555556 0.86111111 0.80555556 0.72222222 0.80555556 0.8\n",
      " 0.91176471 0.88235294 0.88235294 0.82352941]\n",
      "----------------\n",
      "Puntuacion SVM\n",
      "[0.94444444 0.94444444 0.94444444 0.86111111 0.91666667 0.91428571\n",
      " 0.97058824 1.         1.         0.88235294]\n",
      "-----------------\n",
      "Puntuacion TREE\n",
      "[0.88888889 0.86111111 0.91666667 0.72222222 0.86111111 0.85714286\n",
      " 0.97058824 0.91176471 1.         0.88235294]\n",
      "-----------------------------------------------\n",
      "Base de datos: iris.arff\n",
      "Puntuacion KNN\n",
      "[1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "----------------\n",
      "Puntuacion SVM\n",
      "[1.         0.93333333 1.         1.         1.         0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "-----------------\n",
      "Puntuacion TREE\n",
      "[1.         0.93333333 1.         0.93333333 0.93333333 0.86666667\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "-----------------------------------------------\n",
      "Base de datos: more_iris.arff\n",
      "Puntuacion KNN\n",
      "[1.         0.93333333 1.         1.         0.86666667 1.\n",
      " 0.93333333 1.         1.         0.86666667]\n",
      "----------------\n",
      "Puntuacion SVM\n",
      "[1.         0.93333333 1.         1.         1.         0.93333333\n",
      " 0.93333333 0.93333333 1.         0.86666667]\n",
      "-----------------\n",
      "Puntuacion TREE\n",
      "[1.         0.93333333 1.         0.93333333 0.86666667 0.8\n",
      " 0.86666667 1.         1.         0.93333333]\n",
      "-----------------------------------------------\n",
      "Base de datos: segment-challenge.arff\n",
      "Puntuacion KNN\n",
      "[0.94078947 0.91447368 0.95394737 0.95394737 0.91390728 0.94666667\n",
      " 0.88590604 0.91891892 0.91836735 0.96598639]\n",
      "----------------\n",
      "Puntuacion SVM\n",
      "[0.59868421 0.47368421 0.51973684 0.60526316 0.55629139 0.58\n",
      " 0.51006711 0.5        0.57142857 0.54421769]\n",
      "-----------------\n",
      "Puntuacion TREE\n",
      "[0.96710526 0.96710526 0.98684211 0.96710526 0.96688742 0.97333333\n",
      " 0.95973154 0.96621622 0.97959184 0.89795918]\n",
      "-----------------------------------------------\n",
      "Base de datos: segment-test.arff\n",
      "Puntuacion KNN\n",
      "[0.9047619  0.9047619  0.92771084 0.8902439  0.86419753 0.95\n",
      " 0.88607595 0.86075949 0.96202532 0.92405063]\n",
      "----------------\n",
      "Puntuacion SVM\n",
      "[0.46428571 0.35714286 0.43373494 0.37804878 0.39506173 0.375\n",
      " 0.34177215 0.32911392 0.4556962  0.4556962 ]\n",
      "-----------------\n",
      "Puntuacion TREE\n",
      "[0.95238095 0.95238095 0.93975904 0.95121951 0.92592593 0.95\n",
      " 0.92405063 0.91139241 0.96202532 0.94936709]\n",
      "-----------------------------------------------\n",
      "Base de datos: weather.arff\n",
      "Puntuacion KNN\n",
      "[0.75       0.75       0.75       0.5        0.75       1.\n",
      " 0.66666667 0.66666667 0.66666667 1.        ]\n",
      "----------------\n",
      "Puntuacion SVM\n",
      "[0.75       0.75       0.75       0.75       0.75       0.66666667\n",
      " 0.66666667 0.66666667 0.66666667 1.        ]\n",
      "-----------------\n",
      "Puntuacion TREE\n",
      "[0.25       0.75       0.75       0.75       1.         1.\n",
      " 1.         0.66666667 0.66666667 1.        ]\n",
      "-----------------------------------------------\n",
      "Base de datos: weather2.arff\n",
      "Puntuacion KNN\n",
      "[0.4        0.8        0.75       0.66666667 0.33333333 0.66666667\n",
      " 1.         1.         0.66666667 0.66666667]\n",
      "----------------\n",
      "Puntuacion SVM\n",
      "[0.6        0.8        1.         0.66666667 0.66666667 1.\n",
      " 1.         0.66666667 1.         0.66666667]\n",
      "-----------------\n",
      "Puntuacion TREE\n",
      "[0.2        0.8        1.         1.         1.         1.\n",
      " 1.         1.         0.66666667 0.66666667]\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import bagging\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "datasets=listdir('./datasets')\n",
    "\n",
    "print('Aplicando método base: ')\n",
    "\n",
    "for i in datasets:\n",
    "\n",
    "    print('Base de datos: ' + str(i))\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "\n",
    "\n",
    "    # Llamada y entrenamiento del algoritmo KNN\n",
    "    print('Puntuacion KNN')\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    cv_scores=cross_val_score(knn,data,target,cv=10)\n",
    "    print(cv_scores)\n",
    "    print('----------------')\n",
    "\n",
    "\n",
    "    # llamada y entrenamiento algoritmo SVM\n",
    "    print('Puntuacion SVM')\n",
    "    svm = SVC(gamma='auto')\n",
    "    cv_scores = cross_val_score(svm, data, target, cv=10)\n",
    "    print(cv_scores)\n",
    "\n",
    "    print('-----------------')\n",
    "\n",
    "    # llamada y entrenamiento del arbol de decision\n",
    "    print('Puntuacion TREE')\n",
    "    arbol = DecisionTreeClassifier()\n",
    "    cv_scores = cross_val_score(arbol, data, target, cv=10)\n",
    "    print(cv_scores)\n",
    "\n",
    "    print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "Este método hará la cross-validación de la manera más simple.</br>\n",
    "\n",
    "Aunque con el método base hay splits que realizan buenas clasificiones, en ocasiones se produce un sobreentrenamiento ya que se llega a una puntuación del 100%. Algo que puede suceder debido a que muchos de los datasets son muy pequeños y por tanto los splits son más pequeños aún."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 2.2</b></br>\n",
    "Aplique el método de combinación de clasificadores Bagging a cada uno de los conjuntos y anote los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando metodo de combinacion BAGGING\n",
      "Base de datos: contact-lenses.arff\n",
      "Clasificador base:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[1.         0.66666667 0.66666667 0.33333333 1.         0.5\n",
      " 0.5        0.5        0.5        1.        ]\n",
      "------------------------------------------\n",
      "Clasificador base:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[1.         0.33333333 0.66666667 0.33333333 1.         1.\n",
      " 1.         0.5        0.5        1.        ]\n",
      "------------------------------------------\n",
      "Clasificador base:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[1.         1.         0.66666667 0.66666667 1.         0.5\n",
      " 0.5        1.         0.5        1.        ]\n",
      "------------------------------------------\n",
      "Base de datos: diabetes.arff\n",
      "Clasificador base:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[0.63636364 0.77922078 0.68831169 0.63636364 0.76623377 0.79220779\n",
      " 0.71428571 0.83116883 0.69736842 0.69736842]\n",
      "------------------------------------------\n",
      "Clasificador base:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[0.58441558 0.71428571 0.55844156 0.61038961 0.64935065 0.61038961\n",
      " 0.81818182 0.67532468 0.68421053 0.60526316]\n",
      "------------------------------------------\n",
      "Clasificador base:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[0.64935065 0.80519481 0.71428571 0.62337662 0.77922078 0.77922078\n",
      " 0.76623377 0.80519481 0.71052632 0.77631579]\n",
      "------------------------------------------\n",
      "Base de datos: glass.arff\n",
      "Clasificador base:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[0.59090909 0.68181818 0.68181818 0.77272727 0.71428571 0.42857143\n",
      " 0.76190476 0.57142857 0.71428571 0.80952381]\n",
      "------------------------------------------\n",
      "Clasificador base:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[0.54545455 0.54545455 0.59090909 0.54545455 0.71428571 0.57142857\n",
      " 0.9047619  0.76190476 0.52380952 0.66666667]\n",
      "------------------------------------------\n",
      "Clasificador base:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[0.72727273 0.77272727 0.63636364 0.68181818 0.85714286 0.61904762\n",
      " 0.9047619  0.71428571 0.9047619  0.76190476]\n",
      "------------------------------------------\n",
      "Base de datos: ionosphere.arff\n",
      "Clasificador base:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[0.75       0.8        0.68571429 0.74285714 0.82857143 0.82857143\n",
      " 0.74285714 1.         0.97142857 0.97142857]\n",
      "------------------------------------------\n",
      "Clasificador base:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[0.88888889 0.88571429 0.82857143 0.85714286 0.85714286 0.97142857\n",
      " 0.91428571 1.         1.         0.97142857]\n",
      "------------------------------------------\n",
      "Clasificador base:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[0.91666667 0.88571429 0.8        0.88571429 0.77142857 0.97142857\n",
      " 0.88571429 0.97142857 0.91428571 0.97142857]\n",
      "------------------------------------------\n",
      "Base de datos: iris.arff\n",
      "Clasificador base:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[1.         1.         1.         1.         0.86666667 0.86666667\n",
      " 1.         0.86666667 0.8        1.        ]\n",
      "------------------------------------------\n",
      "Clasificador base:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[1.         1.         1.         1.         1.         0.86666667\n",
      " 1.         0.86666667 0.86666667 0.93333333]\n",
      "------------------------------------------\n",
      "Clasificador base:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[1.         1.         1.         1.         0.93333333 0.8\n",
      " 1.         0.86666667 0.73333333 1.        ]\n",
      "------------------------------------------\n",
      "Base de datos: more_iris.arff\n",
      "Clasificador base:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[1.         1.         1.         1.         0.8        0.86666667\n",
      " 0.93333333 0.86666667 0.86666667 0.86666667]\n",
      "------------------------------------------\n",
      "Clasificador base:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[1.         1.         1.         1.         0.86666667 0.86666667\n",
      " 0.93333333 0.93333333 0.8        0.86666667]\n",
      "------------------------------------------\n",
      "Clasificador base:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[1.         1.         0.93333333 1.         0.93333333 0.86666667\n",
      " 0.93333333 0.86666667 1.         0.93333333]\n",
      "------------------------------------------\n",
      "Base de datos: segment-challenge.arff\n",
      "Clasificador base:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[0.96       0.9        0.96       0.96       0.92       0.90666667\n",
      " 0.88666667 0.91333333 0.92666667 0.96      ]\n",
      "------------------------------------------\n",
      "Clasificador base:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[0.56       0.50666667 0.44666667 0.58666667 0.54       0.52666667\n",
      " 0.53333333 0.44666667 0.52666667 0.50666667]\n",
      "------------------------------------------\n",
      "Clasificador base:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[0.98       0.96       0.98666667 0.95333333 0.99333333 0.95333333\n",
      " 0.96       0.96666667 0.97333333 0.95333333]\n",
      "------------------------------------------\n",
      "Base de datos: segment-test.arff\n",
      "Clasificador base:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[0.91358025 0.87654321 0.87654321 0.91358025 0.85185185 0.9382716\n",
      " 0.82716049 0.87654321 0.95061728 0.92592593]\n",
      "------------------------------------------\n",
      "Clasificador base:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[0.32098765 0.37037037 0.4691358  0.38271605 0.34567901 0.41975309\n",
      " 0.32098765 0.44444444 0.34567901 0.32098765]\n",
      "------------------------------------------\n",
      "Clasificador base:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[0.97530864 0.92592593 0.9382716  0.98765432 0.95061728 0.9382716\n",
      " 0.9382716  0.90123457 0.95061728 0.97530864]\n",
      "------------------------------------------\n",
      "Base de datos: weather.arff\n",
      "Clasificador base:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[0.25       0.5        1.         0.75       0.66666667 1.\n",
      " 0.66666667 1.         0.66666667 0.66666667]\n",
      "------------------------------------------\n",
      "Clasificador base:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[0.5        0.5        1.         0.75       0.66666667 1.\n",
      " 0.66666667 1.         0.66666667 0.66666667]\n",
      "------------------------------------------\n",
      "Clasificador base:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[0.25       0.5        1.         1.         1.         1.\n",
      " 0.66666667 0.66666667 1.         0.66666667]\n",
      "------------------------------------------\n",
      "Base de datos: weather2.arff\n",
      "Clasificador base:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[0.25       0.75       0.75       1.         0.25       1.\n",
      " 0.66666667 0.33333333 1.         0.66666667]\n",
      "------------------------------------------\n",
      "Clasificador base:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[0.5        0.75       1.         1.         0.5        1.\n",
      " 0.66666667 0.66666667 1.         0.66666667]\n",
      "------------------------------------------\n",
      "Clasificador base:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[0.25       0.75       1.         0.75       0.75       1.\n",
      " 1.         0.33333333 1.         0.66666667]\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import bagging\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "datasets=listdir('./datasets')\n",
    "\n",
    "print('Aplicando metodo de combinacion BAGGING')\n",
    "\n",
    "for i in datasets:\n",
    "    print('Base de datos: ' + str(i))\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "\n",
    "    for base_estimator in [KNeighborsClassifier(n_neighbors=5),SVC(gamma='auto'),DecisionTreeClassifier()]:\n",
    "        \n",
    "        print('Clasificador base: ', base_estimator)\n",
    "        kfold = model_selection.KFold(n_splits=10)\n",
    "        model = bagging.BaggingClassifier(base_estimator=base_estimator)\n",
    "        results = model_selection.cross_val_score(model, data, target, cv=kfold)\n",
    "        print(results)\n",
    "        print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "El clasificador Bagging es un ensemble que entrena el clasificador base en \"subsets\" aleatórios del dataset original, despues se agrega cada predicción individual para lograr una predicción final. Como es un \"meta-estimador\" se puede utilizar para reducir la varianza de un \"estimador black-box\" como es el caso de los árboles de decisión, ya que introduce la randomización en su procedimiento y después realiza el ensemble.</br>\n",
    "\n",
    "Se puede apreciar como el sobreentrenamiento ha mejorado un poco, no estando tan presente como con el método base, aún así no se llegan a conseguir del todo buenos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 2.3: </b></br>\n",
    "Seleccione dos algoritmos de Boosting y aplique estos algoritmos a cada uno de los conjuntos y anote los\n",
    "resultados obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se ha elegido el algoritmo: GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo de BOOSTING: Classifier\n",
      "Base de datos: contact-lenses.arff\n",
      "[0.66666667 1.         0.66666667 0.66666667 1.         0.5\n",
      " 0.5        0.5        0.5        1.        ]\n",
      "Base de datos: diabetes.arff\n",
      "[0.66233766 0.84415584 0.7012987  0.7012987  0.77922078 0.76623377\n",
      " 0.79220779 0.80519481 0.72368421 0.77631579]\n",
      "Base de datos: glass.arff\n",
      "[0.63636364 0.68181818 0.59090909 0.72727273 0.9047619  0.47619048\n",
      " 0.76190476 0.52380952 0.85714286 0.85714286]\n",
      "Base de datos: ionosphere.arff\n",
      "[0.88888889 0.94285714 0.85714286 0.85714286 0.82857143 0.97142857\n",
      " 0.94285714 1.         0.94285714 0.97142857]\n",
      "Base de datos: iris.arff\n",
      "[0.4        1.         1.         0.93333333 0.66666667 0.86666667\n",
      " 1.         0.86666667 0.8        0.93333333]\n",
      "Base de datos: more_iris.arff\n",
      "[1.         1.         1.         0.93333333 0.73333333 0.86666667\n",
      " 0.93333333 0.86666667 0.86666667 0.86666667]\n",
      "Base de datos: segment-challenge.arff\n",
      "[0.96666667 0.96       0.92666667 0.93333333 0.95333333 0.95333333\n",
      " 0.9        0.94666667 0.96666667 0.94      ]\n",
      "Base de datos: segment-test.arff\n",
      "[0.90123457 0.91358025 0.96296296 0.97530864 0.95061728 0.90123457\n",
      " 0.9382716  0.90123457 0.91358025 0.95061728]\n",
      "Base de datos: weather.arff\n",
      "[0.25       0.75       1.         1.         1.         1.\n",
      " 0.33333333 1.         1.         0.66666667]\n",
      "Base de datos: weather2.arff\n",
      "[0.25       0.75       1.         0.75       0.75       1.\n",
      " 1.         0.66666667 1.         0.66666667]\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import bagging\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "datasets=listdir('./datasets')\n",
    "\n",
    "print('Algoritmo de BOOSTING: Classifier')\n",
    "\n",
    "for i in datasets:\n",
    "\n",
    "    print('Base de datos: ' + str(i))\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "    results = model_selection.cross_val_score(model,data,target,cv=kfold)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En segundo lugar se ha elegido el algoritmo: GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo de BOOSTING: Regressor\n",
      "Base de datos: contact-lenses.arff\n",
      "[-0.73890613  0.76283986  0.62705151  0.49896333  0.45778306  0.\n",
      "  0.          0.30811677 -0.04657561  0.        ]\n",
      "Base de datos: diabetes.arff\n",
      "[0.22788826 0.33672603 0.28638298 0.15466845 0.3219595  0.38980154\n",
      " 0.08840806 0.45342198 0.23153615 0.36699384]\n",
      "Base de datos: glass.arff\n",
      "[0.4830464  0.28842698 0.56667997 0.46063455 0.80821844 0.3487557\n",
      " 0.758704   0.53964508 0.7067462  0.27236181]\n",
      "Base de datos: ionosphere.arff\n",
      "[0.64207865 0.73521442 0.40775591 0.54577165 0.42254568 0.79501384\n",
      " 0.67661616 0.76798428 0.         0.        ]\n",
      "Base de datos: iris.arff\n",
      "[0.         0.         0.         0.93170562 0.         0.\n",
      " 0.99662768 0.         0.         0.        ]\n",
      "Base de datos: more_iris.arff\n",
      "[0.         0.         0.         0.92238771 0.         0.\n",
      " 0.73462532 0.         0.         0.        ]\n",
      "Base de datos: segment-challenge.arff\n",
      "[0.80468227 0.77222944 0.85833423 0.83752294 0.83753892 0.80161699\n",
      " 0.83990573 0.80931783 0.78940847 0.83940477]\n",
      "Base de datos: segment-test.arff\n",
      "[0.86797646 0.80201345 0.78422651 0.88693584 0.8582975  0.85867924\n",
      " 0.7837991  0.83226016 0.8678124  0.8792887 ]\n",
      "Base de datos: weather.arff\n",
      "[-1.35081872 -0.7283414   0.          0.65102659  0.57541774  0.\n",
      " -0.00544883  0.          0.75404045  0.56934273]\n",
      "Base de datos: weather2.arff\n",
      "[-2.75897946  0.15878369  0.          0.09712734 -0.72986032  0.67860187\n",
      "  0.95209317  0.00937212  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import bagging\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "datasets=listdir('./datasets')\n",
    "\n",
    "print('Algoritmo de BOOSTING: Regressor')\n",
    "\n",
    "for i in datasets:\n",
    "\n",
    "    print('Base de datos: ' + str(i))\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    model=GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0, loss='ls')\n",
    "    results=model_selection.cross_val_score(model,data,target,cv=kfold)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "Estos dos métodos consisten en lo siguiente:\n",
    "\n",
    "Se construirá un modelo aditivo de manera progresiva por etapas y permitirá la optimización de funciones arbitrárias de pérdida diferenciable. Cada iteración del algoritmo ajusta un árbol de regresión en el gradiente negativo de la función de pérdida.</br>\n",
    "La diferncia es que uno se utilizará para clasificación y otro para regresión. De ahí las malas puntuaciones al utilizar GradientBoostingRegressor en algunos datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 2.4: </b></br>\n",
    "Compare si hay diferencias significativas entre ellos usando el test de Iman-Davenport. Si es así, aplique el\n",
    "procedimiento de Wilcoxon para comparar cada método de agrupación con el clasificador base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 3: </b></br>\n",
    "Enuncie las conclusiones del estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
