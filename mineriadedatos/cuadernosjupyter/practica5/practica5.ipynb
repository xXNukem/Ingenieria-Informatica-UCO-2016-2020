{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 1 y 2: </b></br>\n",
    "<ul>\n",
    "    <li>Seleccione un algoritmo clasificación de los disponibles en scikit que sea capaz de resolver problemas de más de dos clases y al menos 10 conjuntos de datos de más de 2 clases (puede reusar los de prácticas anteriores).\n",
    "    <li>Aplique el clasificador base a cada uno de los conjuntos y anote los resultados obtenidos\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASIFICADOR BASE KNN\n",
      "Base de datos: contact-lenses.arff\n",
      "Porcentaje de bien clasificados:  0.8\n",
      "Base de datos: cpu.arff\n",
      "Porcentaje de bien clasificados:  0.011904761904761904\n",
      "Base de datos: diabetes.arff\n",
      "Porcentaje de bien clasificados:  0.711038961038961\n",
      "Base de datos: glass.arff\n",
      "Porcentaje de bien clasificados:  0.6627906976744186\n",
      "Base de datos: ionosphere.arff\n",
      "Porcentaje de bien clasificados:  0.851063829787234\n",
      "Base de datos: iris.arff\n",
      "Porcentaje de bien clasificados:  0.9833333333333333\n",
      "Base de datos: more_iris.arff\n",
      "Porcentaje de bien clasificados:  0.9333333333333333\n",
      "Base de datos: segment-challenge.arff\n",
      "Porcentaje de bien clasificados:  0.9216666666666666\n",
      "Base de datos: segment-test.arff\n",
      "Porcentaje de bien clasificados:  0.8549382716049383\n",
      "Base de datos: weather.arff\n",
      "Porcentaje de bien clasificados:  0.6666666666666666\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#ejecutar con python2.7\n",
    "\n",
    "datasets=listdir('./datasets')\n",
    "\n",
    "print('CLASIFICADOR BASE KNN')\n",
    "for i in datasets:\n",
    "\n",
    "    print('Base de datos: ' + str(i))\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "    # llamada y entrenamiento algoritmo SVM\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    print('Porcentaje de bien clasificados: ', knn.score(X_test,Y_test))\n",
    "\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "Aplicamos el método KNN, un buen algoritmo que resuelve problemas multiclase, a continuación haremos las comprobaciones con otras estratégias para este tipo de problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 3: </b></br>\n",
    "Aplique los métodos multiclase one-vs.-one (OVO), one-vs.all (OVA) y error correcting output codes (ECOC) a cada uno de los conjuntos de datos y anote los resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "Primero se muestra el modo 'one-vs-one'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando metodo multiclase ONE VS ONE GAUSSIAN PROCESS CLASSIFIER\n",
      "Base de datos: contact-lenses.arff\n",
      "Porcentaje de bien clasificados:  0.6\n",
      "Base de datos: cpu.arff\n",
      "Porcentaje de bien clasificados:  0.0\n",
      "Base de datos: diabetes.arff\n",
      "Porcentaje de bien clasificados:  0.7077922077922078\n",
      "Base de datos: glass.arff\n",
      "Porcentaje de bien clasificados:  0.6627906976744186\n",
      "Base de datos: ionosphere.arff\n",
      "Porcentaje de bien clasificados:  0.8368794326241135\n",
      "Base de datos: iris.arff\n",
      "Porcentaje de bien clasificados:  0.9666666666666667\n",
      "Base de datos: more_iris.arff\n",
      "Porcentaje de bien clasificados:  0.9\n",
      "Base de datos: segment-challenge.arff\n",
      "Porcentaje de bien clasificados:  0.9083333333333333\n",
      "Base de datos: segment-test.arff\n",
      "Porcentaje de bien clasificados:  0.8888888888888888\n",
      "Base de datos: weather.arff\n",
      "Porcentaje de bien clasificados:  0.5\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#ejecutar con python2.7\n",
    "\n",
    "datasets=listdir('./datasets')\n",
    "\n",
    "print('Aplicando metodo multiclase ONE VS ONE')\n",
    "\n",
    "for i in datasets:\n",
    "\n",
    "    print('Base de datos: ' + str(i))\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "    gpc = OneVsOneClassifier(knn)\n",
    "    gpc.fit(X_train,Y_train)\n",
    "    print('Porcentaje de bien clasificados: ',gpc.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "Ahora se mostrará con el modo 'one-vs-all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando metodo multiclase ONE VS ALL GAUSSIAN PROCESS CLASSIFIER\n",
      "Base de datos: contact-lenses.arff\n",
      "Porcentaje de bien clasificados:  0.4\n",
      "Base de datos: cpu.arff\n",
      "Porcentaje de bien clasificados:  0.011904761904761904\n",
      "Base de datos: diabetes.arff\n",
      "Porcentaje de bien clasificados:  0.5941558441558441\n",
      "Base de datos: glass.arff\n",
      "Porcentaje de bien clasificados:  0.6511627906976745\n",
      "Base de datos: ionosphere.arff\n",
      "Porcentaje de bien clasificados:  0.8226950354609929\n",
      "Base de datos: iris.arff\n",
      "Porcentaje de bien clasificados:  0.9833333333333333\n",
      "Base de datos: more_iris.arff\n",
      "Porcentaje de bien clasificados:  0.9666666666666667\n",
      "Base de datos: segment-challenge.arff\n",
      "Porcentaje de bien clasificados:  0.9083333333333333\n",
      "Base de datos: segment-test.arff\n",
      "Porcentaje de bien clasificados:  0.9104938271604939\n",
      "Base de datos: weather.arff\n",
      "Porcentaje de bien clasificados:  0.5\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#ejecutar con python2.7\n",
    "\n",
    "datasets=listdir('./datasets')\n",
    "\n",
    "print('Aplicando metodo multiclase ONE VS ALL')\n",
    "\n",
    "for i in datasets:\n",
    "\n",
    "    print('Base de datos: ' + str(i))\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "    gpc = OneVsRestClassifier(knn)\n",
    "    gpc.fit(X_train,Y_train)\n",
    "    print('Porcentaje de bien clasificados: ',gpc.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "A continuacion se comentarán estos métodos:\n",
    "<ul>\n",
    "    <li><b>One-vs-rest: </b>Se ajusta cada clasificador de proceso gaussiano para cada clase. Dicha clase será separada del resto.\n",
    "    <li><b>One-vs-one: </b>Se ajusta cada clasificador de proceso gaussiano para cada par de clases. Estas dos clases se separarán del resto. Este método no admitirá la predicción de estimaciones de probabilidad.\n",
    "</ul>\n",
    "\n",
    "Debido a esta forma de manejar la multiclase, se aprecia una mejora en las puntuaciones con respecto al método base en algunos casos. En cambio, en datasets pequeños como 'weather' la puntuación disminuye.</br>\n",
    "También ha incrementado significativamente el tiempo de cómputo con respecto al método base en los datasets más grandes, aunque dado que hay puntuaciones que incrementan, podría merecer la pena utilizar estos métodos en según qué casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "Por último se empleará el método Error Correcting Output Codes (ECOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando metodo multiclase ERROR CORRECTING OUTPUT CODES\n",
      "Base de datos: contact-lenses.arff\n",
      "Porcentaje de bien clasificados:  0.6\n",
      "Base de datos: cpu.arff\n",
      "Porcentaje de bien clasificados:  0.011904761904761904\n",
      "Base de datos: diabetes.arff\n",
      "Porcentaje de bien clasificados:  0.6915584415584416\n",
      "Base de datos: glass.arff\n",
      "Porcentaje de bien clasificados:  0.6162790697674418\n",
      "Base de datos: ionosphere.arff\n",
      "Porcentaje de bien clasificados:  0.8085106382978723\n",
      "Base de datos: iris.arff\n",
      "Porcentaje de bien clasificados:  0.95\n",
      "Base de datos: more_iris.arff\n",
      "Porcentaje de bien clasificados:  0.95\n",
      "Base de datos: segment-challenge.arff\n",
      "Porcentaje de bien clasificados:  0.9066666666666666\n",
      "Base de datos: segment-test.arff\n",
      "Porcentaje de bien clasificados:  0.904320987654321\n",
      "Base de datos: weather.arff\n",
      "Porcentaje de bien clasificados:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#ejecutar con python2.7\n",
    "\n",
    "datasets=listdir('./datasets')\n",
    "\n",
    "print('Aplicando metodo multiclase ERROR CORRECTING OUTPUT CODES')\n",
    "\n",
    "for i in datasets:\n",
    "\n",
    "    print('Base de datos: ' + str(i))\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
    "    \n",
    "    clf = OutputCodeClassifier(KNeighborsClassifier(n_neighbors=5), code_size = 4, random_state = 0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print('Porcentaje de bien clasificados: ',clf.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "Con este método se representa cada clase con un código binaro en una matriz de 0 y 1. Se ajustará un clasificador binario por bit en el 'libro de códigos' y en el momento de la predicción, los clasificadores proyectarán nuevos puntos en el espacio de clase eligidiendo la clase más cercana a los puntos.</br>\n",
    "\n",
    "El modelo utiliza un clasificador base que en este experimento ha sido el KNN. Utilizaremos el atributo 'code_size' para determinar el porcentaje del número de clases que se utilizarán para crear el libro de códigos. Es importante probar este parámetro para ajustarlo lo mejor posible al modelo, ya que podría provocar sobre-entrenamiento. </br>\n",
    "\n",
    "Con respecto a los resultados son bastante similares a los anteriores, además de tener un tiempo de cómputo menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 5: </b></br>\n",
    "Compare si hay diferencias significativas entre ellos usando el test de Iman-Davenport. Si es así, aplique el\n",
    "procedimiento de Wilcoxon para comparar cada método multiclase con el clasificador base y los diferentes\n",
    "métodos entre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de Iman Davenport\n",
      "2.8529862174578917\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from scipy.stats import friedmanchisquare\n",
    "from scipy.stats import rankdata\n",
    "from scipy.stats import f\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#ejecutar con python2.7\n",
    "\n",
    "datasets=listdir('./datasets')\n",
    "\n",
    "scoreBase=[]\n",
    "scoreOnevsone=[]\n",
    "scoreOnevsrest=[]\n",
    "scoreEoc=[]\n",
    "\n",
    "for i in datasets:\n",
    "\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    scoreBase.append(knn.score(X_test,Y_test))\n",
    "\n",
    "\n",
    "for i in datasets:\n",
    "\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "    gpc = OneVsOneClassifier(knn)\n",
    "    gpc.fit(X_train,Y_train)\n",
    "    scoreOnevsone.append(gpc.score(X_test,Y_test))\n",
    "    \n",
    "for i in datasets:\n",
    "\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "    gpc = OneVsRestClassifier(knn)\n",
    "    gpc.fit(X_train,Y_train)\n",
    "    scoreOnevsrest.append(gpc.score(X_test,Y_test))\n",
    "    \n",
    "\n",
    "for i in datasets:\n",
    "\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "    clf = OutputCodeClassifier(KNeighborsClassifier(n_neighbors=5), code_size = 4, random_state = 0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    scoreEoc.append(clf.score(X_test,Y_test))\n",
    "    \n",
    "print('Test de Iman Davenport')\n",
    "nDatasets=10\n",
    "kAlgoritms=4\n",
    "chi=friedmanchisquare(scoreBase,scoreOnevsone,scoreOnevsrest,scoreEoc)\n",
    "F=((nDatasets-1)*chi[0])/(nDatasets*(kAlgoritms-1)-chi[0])\n",
    "RESULT = f.ppf(q=F, dfn=kAlgoritms-1, dfd=(kAlgoritms-1)*(nDatasets-1))\n",
    "if F < RESULT:\n",
    "    print('No hay diferencias importantes')\n",
    "    print('Valor de F: '+str(F)+' , valor de RESULT: '+str(RESULT))\n",
    "elif F > RESULT:\n",
    "    print('Las diferencias son importantes')\n",
    "    print('Valor de F: '+str(F)+' , valor de RESULT: '+str(RESULT))\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "No se ha podido calcular correctamente debido a que se obtiene un \"nan\" en el estadístico, así que para asegurarnos utilizaremos el test de Wilcoxon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de Wilcoxon BASE VS ONE VS ONE\n",
      "WilcoxonResult(statistic=9.5, pvalue=0.06654572134371614)\n",
      "Test de Wilcoxon BASE VS ONE VS REST\n",
      "WilcoxonResult(statistic=16.5, pvalue=0.2621926024067731)\n",
      "Test de Wilcoxon BASE VS ONE VS EOC\n",
      "WilcoxonResult(statistic=22.5, pvalue=0.6100665567498502)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from scipy.stats import friedmanchisquare\n",
    "from scipy.stats import rankdata\n",
    "from scipy.stats import f\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#ejecutar con python2.7\n",
    "\n",
    "datasets=listdir('./datasets')\n",
    "\n",
    "scoreBase=[]\n",
    "scoreOnevsone=[]\n",
    "scoreOnevsrest=[]\n",
    "scoreEoc=[]\n",
    "\n",
    "for i in datasets:\n",
    "\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    scoreBase.append(knn.score(X_test,Y_test))\n",
    "\n",
    "\n",
    "for i in datasets:\n",
    "\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "    gpc = OneVsOneClassifier(knn)\n",
    "    gpc.fit(X_train,Y_train)\n",
    "    scoreOnevsone.append(gpc.score(X_test,Y_test))\n",
    "    \n",
    "for i in datasets:\n",
    "\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "    gpc = OneVsRestClassifier(knn)\n",
    "    gpc.fit(X_train,Y_train)\n",
    "    scoreOnevsrest.append(gpc.score(X_test,Y_test))\n",
    "\n",
    "for i in datasets:\n",
    "\n",
    "    dataset = arff.loadarff('./datasets/' + str(i))\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    data = df.iloc[:, df.columns != 'class']\n",
    "    target = pd.factorize(df['class'])[0]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "    clf = OutputCodeClassifier(KNeighborsClassifier(n_neighbors=5), code_size = 4, random_state = 0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    scoreEoc.append(clf.score(X_test,Y_test))\n",
    "    \n",
    "print('Test de Wilcoxon BASE VS ONE VS ONE')\n",
    "print(wilcoxon(x=scoreBase, y=scoreOnevsone, zero_method='zsplit', correction=False))\n",
    "print('Test de Wilcoxon BASE VS ONE VS REST')\n",
    "print(wilcoxon(x=scoreBase, y=scoreOnevsrest, zero_method='zsplit', correction=False))\n",
    "print('Test de Wilcoxon BASE VS ONE VS EOC')\n",
    "print(wilcoxon(x=scoreBase, y=scoreEoc, zero_method='zsplit', correction=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "En esta caso si existe bastante similadridad en las muestras tomadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 7: </b></br>\n",
    "Enuncie las conclusiones del estudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b></br>\n",
    "\n",
    "Hemos utilizado metodologías que son capaces de transformar problemas de N clases en M problemas de dos clases. El funcionamiento de estos algoritmos ha sido explicado anteriormente. </br>\n",
    "\n",
    "Para empezar, el clasificador base utilizado es el KNN, cuyo número de vecinos deberia estudiarse para proporcionar el rendimiento óptimo en cada problema pero, en los algoritmos siguientes, en ocasiones hay que disminuir el número de vecinos ya que no puede ser mayor que el número de muestras que estos algoritmos toman.</br>\n",
    "\n",
    "En primer lugar se hace notar el incremento del  tiempo de computo que tienen estos métodos (aunque el tiempo aumenta de utilizar algoritmos como el GradientBoosting en modo One VS Rest o One VS One). Además la puntuación no varía en exceso con las obtenidas en prácticas anteriores, con lo que, anoser que sea necesario, se debería estudiar si es conveniente utilizar otro método. Ya que sobre todo en datasets grandes esto puede ser un problema considerable, y puede ser conveniente utilizar un método que de un error ligéramente mayor a cambio de tardar mucho menos.</b>\n",
    "\n",
    "Apreciamos que, concrétamente, la estratégia One VS One resulta ser la más lenta de todas. Esto sucede porque requiere entrenar n_classes * (n_classes - 1) / 2 clasificadores. Lo que nos deja una complejidad computacional de O(n_classes^2). Sin embargo, es un método al que se le puede sacar beneficion si el Kernel no escala bien con el número de muestras del dataset.</br>\n",
    "\n",
    "Al final, la estratégia One VS Rest termina siendo más util debido a que entrena un clasificador por clase, reduciendo por tanto el tiempo computacional de manera considerable. Además el modelo termina siendo mucho más interpretable que el anterior. Por tanto, se convierte en una muy buena opción para resolver este tipo de problemas. Lo que sí es evidente en ambos métodos es que, a mayor número de clases, más tiempo le tomará al algoritmo computar el modelo.</br>\n",
    "\n",
    "Por último el método Output Code Classifier, realiza una binarización de las clases. Lo cual es una buena estratégia para resolver problemas multiclase, aunque dicha binarización también se podría realizar en un preprocesado del dataset. Lo que nos llevaría a menor tiempo de cómputo de utilizar otro algoritmo.</br>\n",
    "\n",
    "Sin embargo, encontramos una buena ventaja a la hora de utilizar este método, y es que es posible controlar el número de clasificadores que utilizará el algoritmo, esto se hará con el parámetro code_size. Esto parámetro puede conseguir que el modelo sea más robusto de cara a los errores y moderar el tiempo computacional, siempre y cuando lo estudiemos para el problema que estamos tratando.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
